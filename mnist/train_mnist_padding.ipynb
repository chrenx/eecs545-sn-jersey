{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import timeit\n",
    "import unittest\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define a transforms for preparing the dataset\n",
    "transform = transforms.Compose([\n",
    "\n",
    "transforms.CenterCrop(26),\n",
    "# transforms.Resize((150,150)),\n",
    "# transforms.Resize((250, 250)),\n",
    "transforms.Pad(80),\n",
    "transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "transforms.Grayscale(1),\n",
    "transforms.RandomRotation(10),      \n",
    "transforms.RandomAffine(5),\n",
    "transforms.RandomPerspective(distortion_scale=0.65, p=0.8),\n",
    "transforms.ElasticTransform(),\n",
    "transforms.GaussianBlur(kernel_size=(3,3)),\n",
    "transforms.Resize((200,200)),\n",
    "\n",
    "# convert the image to a pytorch tensor\n",
    "transforms.ToTensor(), \n",
    "\n",
    "# normalise the images with mean and std of the dataset\n",
    "transforms.Normalize((0.1307,), (0.3081,)) \n",
    "])\n",
    "\n",
    "# Load the MNIST training, test datasets using `torchvision.datasets.MNIST` \n",
    "# using the transform defined above\n",
    "\n",
    "train_dataset = datasets.MNIST('./data_padding',train=True,transform=transform,download=True)\n",
    "test_dataset =  datasets.MNIST('./data_padding',train=False,transform=transform,download=True)\n",
    "\n",
    "# create dataloaders for training and test datasets\n",
    "# use a batch size of 32 and set shuffle=True for the training set\n",
    "\n",
    "train_dataloader = Data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader = Data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=True) \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 200, 200]),\n",
       " torch.float32,\n",
       " tensor(5),\n",
       " torch.Size([1, 200, 200]),\n",
       " <matplotlib.image.AxesImage at 0x7c21b025c670>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a= next(iter(train_dataloader))\n",
    "b = a[0][0].detach().clone()\n",
    "a[0].shape, a[0].dtype, a[1][0], b.shape, plt.imshow(b.permute(1,2,0), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #! 210 input\n",
    "        # define a conv layer with output channels as 16\n",
    "        self.conv11 = nn.Conv2d(1, 16, 6, 2) \n",
    "        self.conv12 = nn.Conv2d(1, 16, 10, 2)\n",
    "        self.conv13 = nn.Conv2d(1, 16, 14, 2) \n",
    "        self.conv14 = nn.Conv2d(1, 16, 18, 2) \n",
    "\n",
    "        # define a conv layer with output channels as 32\n",
    "        self.conv21 = nn.Conv2d(16, 32, 3, 2)\n",
    "        self.conv22 = nn.Conv2d(16, 32, 5, 2)\n",
    "        self.conv23 = nn.Conv2d(16, 32, 7, 2) \n",
    "        self.conv24 = nn.Conv2d(16, 32, 9, 2) \n",
    "\n",
    "        # define a conv layer with output channels as 64\n",
    "        self.conv31 = nn.Conv2d(32, 64, 3, 2) \n",
    "        self.conv32 = nn.Conv2d(32, 64, 5, 2) \n",
    "        self.conv33 = nn.Conv2d(32, 64, 7, 2)\n",
    "        self.conv34 = nn.Conv2d(32, 64, 9, 2)\n",
    "\n",
    "        self.conv41 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.conv42 = nn.Conv2d(64, 128, 5, 1)\n",
    "        self.conv43 = nn.Conv2d(64, 128, 7, 1) \n",
    "        self.conv44 = nn.Conv2d(64, 128, 9, 1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # define a max pooling layer with kernel size 2\n",
    "        self.maxpool = nn.MaxPool2d(2) \n",
    "        # define dropout layer with a probability of 0.25\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        # define dropout layer with a probability of 0.5\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # define a linear(dense) layer with 128 output features\n",
    "        self.fc11 = nn.Linear(128*10*10, 256)\n",
    "        self.fc12 = nn.Linear(128*8*8, 256)\n",
    "        self.fc13 = nn.Linear(128*6*6, 256)\n",
    "        self.fc14 = nn.Linear(128*4*4, 256)\n",
    "\n",
    "        # define a linear(dense) layer with output features corresponding to the number of classes in the dataset\n",
    "        self.fc21 = nn.Linear(256, 128)\n",
    "        self.fc22 = nn.Linear(256, 128)\n",
    "        self.fc23 = nn.Linear(256, 128)\n",
    "        self.fc24 = nn.Linear(256, 128)\n",
    "\n",
    "        self.fc33 = nn.Linear(128*4,10)\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # Use the layers defined above in a sequential way (folow the same as the layer definitions above) and \n",
    "        # write the forward pass, after each of conv1, conv2, conv3 conv4 and fc1 use a relu activation. \n",
    "\n",
    "        x = F.relu(self.conv11(inp))\n",
    "        x = F.relu(self.conv21(x))\n",
    "        x = F.relu(self.conv31(x))\n",
    "        x = F.relu(self.maxpool(self.conv41(x)))\n",
    "\n",
    "        x = x.view(-1,128*10*10)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc11(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc21(x)\n",
    "\n",
    "        y = F.relu(self.conv12(inp))\n",
    "        y = F.relu(self.conv22(y))\n",
    "        y = F.relu(self.conv32(y))\n",
    "        y = F.relu(self.maxpool(self.conv42(y)))\n",
    "\n",
    "        \n",
    "        y = y.view(-1,128*8*8)\n",
    "        y = self.dropout1(y)\n",
    "        y = F.relu(self.fc12(y))\n",
    "        y = self.dropout2(y)\n",
    "        y = self.fc22(y)\n",
    "\n",
    "        z = F.relu(self.conv13(inp))\n",
    "        z = F.relu(self.conv23(z))\n",
    "        z = F.relu(self.conv33(z))\n",
    "        z = F.relu(self.maxpool(self.conv43(z)))\n",
    "\n",
    "        z = z.view(-1,128*6*6)\n",
    "        z = self.dropout1(z)\n",
    "        z = F.relu(self.fc13(z))\n",
    "        z = self.dropout2(z)\n",
    "        z = self.fc23(z)\n",
    "\n",
    "        ze = F.relu(self.conv14(inp))\n",
    "        ze = F.relu(self.conv24(ze))\n",
    "        ze = F.relu(self.conv34(ze))\n",
    "        ze = F.relu(self.maxpool(self.conv44(ze)))\n",
    "\n",
    "        ze = ze.view(-1,128*4*4)\n",
    "        ze = self.dropout1(ze)\n",
    "        ze = F.relu(self.fc14(ze))\n",
    "        ze = self.dropout2(ze)\n",
    "        ze = self.fc24(ze)\n",
    "  \n",
    "        out_f = torch.cat((x, y, z, ze), dim=1)\n",
    "\n",
    "        out = self.fc33(out_f)\n",
    "\n",
    "        output = F.log_softmax(out, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv11): Conv2d(1, 16, kernel_size=(6, 6), stride=(2, 2))\n",
       "  (conv12): Conv2d(1, 16, kernel_size=(10, 10), stride=(2, 2))\n",
       "  (conv13): Conv2d(1, 16, kernel_size=(14, 14), stride=(2, 2))\n",
       "  (conv14): Conv2d(1, 16, kernel_size=(18, 18), stride=(2, 2))\n",
       "  (conv21): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (conv22): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv23): Conv2d(16, 32, kernel_size=(7, 7), stride=(2, 2))\n",
       "  (conv24): Conv2d(16, 32, kernel_size=(9, 9), stride=(2, 2))\n",
       "  (conv31): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (conv32): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv33): Conv2d(32, 64, kernel_size=(7, 7), stride=(2, 2))\n",
       "  (conv34): Conv2d(32, 64, kernel_size=(9, 9), stride=(2, 2))\n",
       "  (conv41): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv42): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv43): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (conv44): Conv2d(64, 128, kernel_size=(9, 9), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc11): Linear(in_features=12800, out_features=256, bias=True)\n",
       "  (fc12): Linear(in_features=8192, out_features=256, bias=True)\n",
       "  (fc13): Linear(in_features=4608, out_features=256, bias=True)\n",
       "  (fc14): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (fc21): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc22): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc23): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc24): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc33): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_1 = []\n",
    "losses_2 = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send the image, target to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # flush out the gradients stored in optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # pass the image to the model and assign the output to variable named output\n",
    "        output = model(data)\n",
    "        # calculate the loss (use nll_loss in pytorch)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # do a backward pass\n",
    "        loss.backward()\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            losses_1.append(loss.item())\n",
    "            losses_2.append(100. * batch_idx / len(train_loader))\n",
    "\n",
    "accuracy = []\n",
    "avg_loss = []\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "          \n",
    "            # send the image, target to the device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # pass the image to the model and assign the output to variable named output\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "          \n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    avg_loss.append(test_loss)\n",
    "    accuracy.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Net().to(device)\n",
    "learning_rate = []\n",
    "def adjust_learning_rate(optimizer, iter, each):\n",
    "    # sets the learning rate to the initial LR decayed by 0.1 every 'each' iterations\n",
    "    lr = 0.001 * (0.95 ** (iter // each))\n",
    "    state_dict = optimizer.state_dict()\n",
    "    for param_group in state_dict['param_groups']:\n",
    "        param_group['lr'] = lr\n",
    "    optimizer.load_state_dict(state_dict)\n",
    "    print(\"Learning rate = \",lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "## Define Adam Optimiser with a learning rate of 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for epoch in range(0,120):\n",
    "  lr = adjust_learning_rate(optimizer, epoch, 1.616)\n",
    "  learning_rate.append(lr)\n",
    "  train(model, device, train_dataloader, optimizer, epoch)\n",
    "  test(model, device, test_dataloader)\n",
    "  if (epoch + 1) % 10 == 0:\n",
    "    torch.save(\n",
    "        {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, \n",
    "        f\"mnist_model_padding_ckpt_E{epoch}.pth\"\n",
    "    )\n",
    "stop = timeit.default_timer()\n",
    "print('Total time taken: {} seconds'.format(int(stop - start)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, \n",
    "    \"mnist_model_ckpt.pth\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soccernet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
